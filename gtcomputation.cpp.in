#define STRUCTURED_GRIDS

#include <gridtools/common/defs.hpp>
#include <gridtools/stencil-composition/stencil-composition.hpp>

#include <pybind11/pybind11.h>
#include <pybind11/stl.h>

#include <array>
#include <cassert>
#include <stdexcept>

namespace gt = ::gridtools;
namespace py = ::pybind11;

namespace {{ module_name }} {

namespace {

struct {{ stencil_name }}_1_functor {
    using out = gt::accessor<0, gt::enumtype::inout>;
    using in = gt::accessor<1, gt::enumtype::in, gt::extent<-1, 0, -1, 0>>;
    using arg_list = boost::mpl::vector<out, in>;

    template <typename Evaluation>
    GT_FUNCTION static void Do(Evaluation &eval) {
        eval(out()) = eval(in(-1, -1, 0));
    }
};

static constexpr gt::uint_t halo_size = {{ halo_size }};
using float_t = {{ float_t }};

using backend_t = gt::backend<gt::target::x86, gt::grid_type::structured,
                              gt::strategy::block>;

gt::halo_descriptor make_halo_descriptor(gt::uint_t outer_size,
                                         gt::uint_t halo_size) {
    return {halo_size, halo_size, halo_size, outer_size - halo_size - 1,
            outer_size};
}

// TODO: We need to find a way how to define the vertical, which intervals
// we want, who defines the sizes of them, and whether we want to have
// additional layers on top / bottom (LevelOffsetLimit of axis)
auto make_grid(const std::array<gt::uint_t, 3>& size)
    GT_AUTO_RETURN(gt::make_grid(make_halo_descriptor(size[0], halo_size),
                                 make_halo_descriptor(size[1], halo_size),
                                 size[2]));

using storage_info_t =
    gt::storage_traits<backend_t::backend_id_t>::custom_layout_storage_info_t<
        0, typename gt::get_layout<3, true>::type,
        gt::halo<halo_size, halo_size, 0>>;
using data_store_t =
    gt::storage_traits<backend_t::backend_id_t>::data_store_t<float_t,
                                                              storage_info_t>;
{% for id, param in input_params -%}
using p_{{ param}} = gt::arg<{{ id }}, data_store_t>;
{% endfor %}

template <typename Grid>
auto make_computation(const Grid& grid)
    GT_AUTO_RETURN(gt::make_computation<backend_t>(
        grid,
        gt::make_multistage(gt::enumtype::execute<gt::enumtype::forward>(),
                            gt::make_stage<{{ stencil_name }}_1_functor>(
                                p_f_out(), p_f_in()))));

data_store_t make_data_store(py::buffer& b,
                             const std::array<gt::uint_t, 3>& outer_size,
                             const std::array<gt::uint_t, 3>& origin) {
    auto buffer_info = b.request();

    if (buffer_info.format != py::format_descriptor<float_t>::format()) {
        throw std::runtime_error(
            "Wrong real type: " + buffer_info.format +
            " != " + py::format_descriptor<float_t>::format());
    }

    if (buffer_info.ndim != 3) {
        throw std::runtime_error("Wrong number of dimensions [" +
                                 std::to_string(buffer_info.ndim) +
                                 " != " + std::to_string(3) + "]");
    }

    for (int i = 0; i < 3; ++i) {
        if (i < 2 && outer_size[i] <= 2 * halo_size)
            throw std::runtime_error(
                "Invalid domain size. Compute domain must be non-empty "
                "(domain size > 2 * halo-size)");

        if (origin[i] + outer_size[i] > buffer_info.shape[i])
            throw std::runtime_error(
                "Given shape and origin exceed buffer dimension");
    }

    // ptr, dims and strides are "outer domain" (i.e., compute domain + halo
    // region). The halo region is only defined through `make_grid` (and
    // currently, in the storage info)
    float_t* ptr = static_cast<float_t*>(buffer_info.ptr);
    gt::array<gt::uint_t, 3> dims{};
    gt::array<gt::uint_t, 3> strides{};
    for (int i = 0; i < 3; ++i) {
        strides[i] = buffer_info.strides[i] / sizeof(float_t);
        ptr += strides[i] * origin[i];
        dims[i] = outer_size[i];
    }
    return data_store_t{storage_info_t{dims, strides}, ptr,
                        gt::ownership::ExternalCPU};
}

}  // namespace

// Note: The GTComputation object is expensive to be created and should not be
// recreated over and over again. Usually we will only call a computation with
// one size. If this is not the case, we should cache the most recent
// GTComputation objects on python side (@lru_cache probably). I don't see the
// point in supporting this here, because we impose an additional requirement
// here which is not needed in general.
class GTComputation {
   public:
    GTComputation(std::array<gt::uint_t, 3> size, gt::uint_t halo)
        : size_(size),
          computation_(make_computation(make_grid(size))) {
        // TODO the halo_size will not be compile-time anymore at a certain
        // point. Currently we just want the user to pass it to verify if he is
        // really doing what he intends to do. In fact, I think we don't care
        // that much about this, because we can calculate the halo size when we
        // create the computation. There is nothing we can gain when passing a
        // different halo size every time. This number will be internal anyway.
        //
        // Currently, we require that halo_sizes the same on both sides, i.e.,
        // halo_left == halo_right and halo_front == halo_back. This restriction
        // will disappear when the halo region is only controlled by the halo
        // descriptors. But again, this is only an internal requirement (with
        // very small limitations from user perspective).
        assert(halo == halo_size);
    }

    {% set comma = joiner(",") -%}
    void run({%- for id, param in input_params -%}
             {{- comma() }}
             py::buffer b_{{ param }}
             {{- comma() }} const std::array<gt::uint_t, 3>& {{ param }}_origin
             {%- endfor -%}) {
        // Initialize data stores from input buffers
        {% for id, param in input_params -%}
        auto ds_{{ param }} = make_data_store(b_{{ param }}, size_, {{ param }}_origin);
        {% endfor -%}

        // Run computation and wait for the synchronization of the output stores
        {% set comma = joiner(", ") -%}
        computation_.run({%- for id, param in input_params -%}
                         {{ comma() }}p_{{ param }}() = ds_{{ param }}
                         {%- endfor %});
        computation_.sync_bound_data_stores();
    }

   private:
    gt::computation<void,
        {%- set comma = joiner(", ") -%}
        {%- for id, param in input_params -%}
        {{ comma() }} p_{{ param }}
        {%- endfor -%}
        > computation_;
    const std::array<gt::uint_t, 3> size_;
};

}  // namespace {{ module_name }}

static constexpr std::array<gt::uint_t, 3> zero_origin{0, 0, 0};
PYBIND11_MODULE({{ module_name }}, m) {
    py::class_<{{ module_name }}::GTComputation>(m, "GTComputation")
        .def(py::init<std::array<gt::uint_t, 3>, gt::uint_t>(),
             py::arg("shape"), py::arg("halo"))
        .def("run", &{{ module_name }}::GTComputation::run,
             {%- set comma = joiner(",") -%}
             {%- for id, param in input_params -%}
             {{- comma()}}
             py::arg("{{ param }}") {{- comma() }} py::arg("{{ param }}_origin") = zero_origin
             {%- endfor -%});
}
